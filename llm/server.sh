python -m llama_cpp.server --model "data/models/mistral-7b-openorca.Q4_K_M.gguf" --chat_format chatml --n_gpu_layers 1
